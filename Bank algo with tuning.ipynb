{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bank algo with tuning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y6Wi4hTj-kiS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":131},"outputId":"75e9d918-0014-4fb3-e4d3-5fe69b461fd3","executionInfo":{"status":"ok","timestamp":1563955399003,"user_tz":-330,"elapsed":27611,"user":{"displayName":"shashank menon","photoUrl":"https://lh6.googleusercontent.com/-Pj5jJ84CPaA/AAAAAAAAAAI/AAAAAAAAARU/73cooQSfVeA/s64/photo.jpg","userId":"12724423519570758874"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9UxsUxbg97fU","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Churn_Modelling.csv')\n","X = dataset.iloc[:,3:13].values\n","Y = dataset.iloc[:,13].values\n","\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","ct = ColumnTransformer([(\"Encoding\",OneHotEncoder(),[1,2])],remainder = \"passthrough\")\n","X = ct.fit_transform(X)\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n","sc = StandardScaler()\n","X_train = np.array(X_train,dtype = np.float64)\n","X_train = sc.fit_transform(X_train)\n","X_test = np.array(X_test,dtype = np.float64)\n","X_test = sc.fit_transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYGjN2Uu-Gow","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"6085c281-d560-4910-a839-711c667cb09e","executionInfo":{"status":"ok","timestamp":1563955419035,"user_tz":-330,"elapsed":2708,"user":{"displayName":"shashank menon","photoUrl":"https://lh6.googleusercontent.com/-Pj5jJ84CPaA/AAAAAAAAAAI/AAAAAAAAARU/73cooQSfVeA/s64/photo.jpg","userId":"12724423519570758874"}}},"source":["from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","from keras.models import Sequential\n","from keras.layers import Dense\n","def buildclassifier(optimizer):\n","    classifier = Sequential()\n","    classifier.add(Dense(6,input_dim=13,activation= 'relu'))\n","    classifier.add(Dense(6,activation = 'relu'))\n","    classifier.add(Dense(1,activation = 'relu'))\n","    classifier.compile(optimizer = optimizer,loss = 'binary_crossentropy',metrics = ['accuracy'])\n","    return classifier"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zArH4mSq-K1x","colab_type":"code","colab":{}},"source":["classif = KerasClassifier(build_fn = buildclassifier)\n","parameters = {'batch_size':[10,16,32],\n","              'nb_epoch' : [100,200],\n","              'optimizer' : ['adam','rmsprop']}\n","grid_search = GridSearchCV(estimator = classif,\n","                          param_grid = parameters,\n","                          scoring = 'accuracy',\n","                          cv = 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"46EdOQ4O-Non","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"17231138-34da-410f-be50-a2fbbf8d27e6","executionInfo":{"status":"ok","timestamp":1563956204613,"user_tz":-330,"elapsed":781103,"user":{"displayName":"shashank menon","photoUrl":"https://lh6.googleusercontent.com/-Pj5jJ84CPaA/AAAAAAAAAAI/AAAAAAAAARU/73cooQSfVeA/s64/photo.jpg","userId":"12724423519570758874"}}},"source":["grid_search = grid_search.fit(X_train,Y_train)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0724 08:02:59.740891 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0724 08:02:59.794313 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0724 08:02:59.802155 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0724 08:02:59.855615 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0724 08:02:59.881668 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0724 08:02:59.888804 139682988447616 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0724 08:03:00.143260 139682988447616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","7200/7200 [==============================] - 2s 215us/step - loss: 2.0276 - acc: 0.7706\n","Epoch 1/1\n","7200/7200 [==============================] - 1s 152us/step - loss: 1.4107 - acc: 0.7686\n","Epoch 1/1\n","7200/7200 [==============================] - 1s 164us/step - loss: 3.2953 - acc: 0.7956\n","Epoch 1/1\n","7200/7200 [==============================] - 1s 172us/step - loss: 1.3593 - acc: 0.6917\n","Epoch 1/1\n","7200/7200 [==============================] - 1s 192us/step - loss: 1.1211 - acc: 0.7276\n","Epoch 1/1\n","7200/7200 [==============================] - 1s 203us/step - loss: 1.3181 - acc: 0.7276\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 216us/step - loss: 3.3453 - acc: 0.5194\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 218us/step - loss: 1.4315 - acc: 0.7683\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 223us/step - loss: 3.2930 - acc: 0.7957\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 237us/step - loss: 3.5839 - acc: 0.5701\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 236us/step - loss: 2.2337 - acc: 0.7251\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 230us/step - loss: 1.5671 - acc: 0.7835\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 240us/step - loss: 0.8988 - acc: 0.7447\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 252us/step - loss: 2.2383 - acc: 0.7507\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 255us/step - loss: 2.1061 - acc: 0.7812\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 269us/step - loss: 0.7105 - acc: 0.7721\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 283us/step - loss: 1.8039 - acc: 0.7583\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 285us/step - loss: 3.2841 - acc: 0.7962\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 294us/step - loss: 1.3784 - acc: 0.7789\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 301us/step - loss: 3.2778 - acc: 0.7961\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 315us/step - loss: 1.9797 - acc: 0.6978\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 324us/step - loss: 0.9648 - acc: 0.7261\n","Epoch 1/1\n","7200/7200 [==============================] - 2s 335us/step - loss: 2.0106 - acc: 0.6492\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 349us/step - loss: 1.9012 - acc: 0.7700\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 363us/step - loss: 1.0183 - acc: 0.7535\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 381us/step - loss: 1.1868 - acc: 0.7599\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 385us/step - loss: 2.8541 - acc: 0.7778\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 396us/step - loss: 2.2778 - acc: 0.7475\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 410us/step - loss: 2.6059 - acc: 0.6719\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 414us/step - loss: 3.2863 - acc: 0.7961\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 414us/step - loss: 2.0952 - acc: 0.7871\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 420us/step - loss: 2.0716 - acc: 0.7304\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 431us/step - loss: 0.9838 - acc: 0.7883\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 441us/step - loss: 3.1936 - acc: 0.7975\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 446us/step - loss: 0.7867 - acc: 0.7737\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 454us/step - loss: 2.7813 - acc: 0.7914\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 462us/step - loss: 0.6195 - acc: 0.7860\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 472us/step - loss: 2.4530 - acc: 0.7883\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 479us/step - loss: 1.5763 - acc: 0.7528\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 486us/step - loss: 1.0285 - acc: 0.7897\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 447us/step - loss: 0.9377 - acc: 0.7222\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 459us/step - loss: 2.5873 - acc: 0.7967\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 468us/step - loss: 3.2953 - acc: 0.7956\n","Epoch 1/1\n","7200/7200 [==============================] - 3s 474us/step - loss: 2.1817 - acc: 0.7461\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 487us/step - loss: 0.5798 - acc: 0.7908\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 496us/step - loss: 1.4656 - acc: 0.7889\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 507us/step - loss: 1.0778 - acc: 0.7589\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 513us/step - loss: 3.1222 - acc: 0.7669\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 538us/step - loss: 2.3871 - acc: 0.6189\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 555us/step - loss: 1.6883 - acc: 0.7478\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 543us/step - loss: 2.6935 - acc: 0.7949\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 545us/step - loss: 1.0131 - acc: 0.7228\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 559us/step - loss: 3.2953 - acc: 0.7956\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 560us/step - loss: 0.6395 - acc: 0.7769\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 568us/step - loss: 2.0888 - acc: 0.6607\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 574us/step - loss: 3.2783 - acc: 0.7944\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 585us/step - loss: 2.8065 - acc: 0.7956\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 593us/step - loss: 1.5837 - acc: 0.7494\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 596us/step - loss: 2.6067 - acc: 0.7903\n","Epoch 1/1\n","7200/7200 [==============================] - 4s 609us/step - loss: 3.2863 - acc: 0.7961\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 633us/step - loss: 0.9284 - acc: 0.7778\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 637us/step - loss: 3.2773 - acc: 0.7967\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 651us/step - loss: 3.2953 - acc: 0.7956\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 657us/step - loss: 2.1870 - acc: 0.7347\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 669us/step - loss: 0.7899 - acc: 0.7864\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 679us/step - loss: 2.6564 - acc: 0.5774\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 687us/step - loss: 1.2112 - acc: 0.7593\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 701us/step - loss: 1.8307 - acc: 0.7933\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 721us/step - loss: 1.1444 - acc: 0.7754\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 728us/step - loss: 1.4386 - acc: 0.7917\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 743us/step - loss: 1.3200 - acc: 0.7717\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 738us/step - loss: 2.0719 - acc: 0.7842\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 737us/step - loss: 2.3972 - acc: 0.7717\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 749us/step - loss: 1.9698 - acc: 0.7761\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 766us/step - loss: 3.3244 - acc: 0.7937\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 763us/step - loss: 1.6452 - acc: 0.7626\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 770us/step - loss: 2.0932 - acc: 0.7922\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 763us/step - loss: 2.3038 - acc: 0.7775\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 784us/step - loss: 2.4712 - acc: 0.7929\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 786us/step - loss: 3.0772 - acc: 0.6482\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 725us/step - loss: 1.7916 - acc: 0.7650\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 744us/step - loss: 1.8678 - acc: 0.6775\n","Epoch 1/1\n","7200/7200 [==============================] - 5s 761us/step - loss: 1.6761 - acc: 0.7597\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 773us/step - loss: 1.6311 - acc: 0.7028\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 767us/step - loss: 3.0816 - acc: 0.7937\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 789us/step - loss: 2.5033 - acc: 0.7935\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 785us/step - loss: 2.0746 - acc: 0.6911\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 808us/step - loss: 0.9691 - acc: 0.7465\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 818us/step - loss: 1.4851 - acc: 0.6276\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 835us/step - loss: 2.5486 - acc: 0.6368\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 827us/step - loss: 2.4893 - acc: 0.7972\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 836us/step - loss: 1.4007 - acc: 0.7735\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 853us/step - loss: 1.6202 - acc: 0.7424\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 851us/step - loss: 2.8518 - acc: 0.7975\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 850us/step - loss: 1.3098 - acc: 0.7474\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 858us/step - loss: 2.0002 - acc: 0.7943\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 859us/step - loss: 2.8787 - acc: 0.7043\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 877us/step - loss: 0.7177 - acc: 0.7657\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 876us/step - loss: 1.0691 - acc: 0.7526\n","Epoch 1/1\n","7200/7200 [==============================] - 6s 887us/step - loss: 2.1412 - acc: 0.7594\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 913us/step - loss: 1.5435 - acc: 0.7468\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 952us/step - loss: 4.7425 - acc: 0.3979\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 939us/step - loss: 2.4292 - acc: 0.7303\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 936us/step - loss: 1.2519 - acc: 0.7924\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 953us/step - loss: 2.1456 - acc: 0.7879\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 956us/step - loss: 2.4781 - acc: 0.7317\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 981us/step - loss: 2.1251 - acc: 0.6665\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 977us/step - loss: 2.2848 - acc: 0.7390\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 988us/step - loss: 1.0841 - acc: 0.7771\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 1.7632 - acc: 0.7304\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 993us/step - loss: 0.6615 - acc: 0.7728\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 999us/step - loss: 1.3175 - acc: 0.7676\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 1.5998 - acc: 0.7828\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 2.4286 - acc: 0.7839\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 1.5774 - acc: 0.7418\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 1.4840 - acc: 0.7704\n","Epoch 1/1\n","7200/7200 [==============================] - 8s 1ms/step - loss: 1.8722 - acc: 0.7510\n","Epoch 1/1\n","7200/7200 [==============================] - 7s 1ms/step - loss: 3.2823 - acc: 0.7962\n","Epoch 1/1\n","7200/7200 [==============================] - 8s 1ms/step - loss: 1.9884 - acc: 0.7461\n","Epoch 1/1\n","7200/7200 [==============================] - 8s 1ms/step - loss: 2.0330 - acc: 0.7731\n","Epoch 1/1\n","8000/8000 [==============================] - 9s 1ms/step - loss: 0.5121 - acc: 0.7985\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"djzPJSch-SPx","colab_type":"code","colab":{}},"source":["best_parameters = grid_search.best_params_\n","best_acc = grid_search.best_score_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXKkOkgGEQSy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"f632a378-2a2d-4f5e-affe-92cd6da86571","executionInfo":{"status":"ok","timestamp":1563956435967,"user_tz":-330,"elapsed":2500,"user":{"displayName":"shashank menon","photoUrl":"https://lh6.googleusercontent.com/-Pj5jJ84CPaA/AAAAAAAAAAI/AAAAAAAAARU/73cooQSfVeA/s64/photo.jpg","userId":"12724423519570758874"}}},"source":["best_acc"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.792125"]},"metadata":{"tags":[]},"execution_count":8}]}]}